{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d11c2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec45f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2336390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15eb5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Outcome',axis=1).values\n",
    "y=df['Outcome'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3965ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c398ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7007fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=torch.FloatTensor(X_train)\n",
    "X_test=torch.FloatTensor(X_test)\n",
    "y_train=torch.LongTensor(y_train)\n",
    "y_test=torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678927b5",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8399b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,input_features=8,hidden1=8,hidden2=200,hidden3=200,hidden4=300,hidden5=300,hidden6=400,hidden7=400,hidden8=300,hidden9=300,out_features=2):\n",
    "        super().__init__()\n",
    "        self.f_connected1=nn.Linear(input_features,hidden1)\n",
    "        self.f_connected2=nn.Linear(hidden1,hidden2)\n",
    "        self.f_connected3=nn.Linear(hidden2,hidden3)\n",
    "        self.f_connected4=nn.Linear(hidden3,hidden4)\n",
    "        self.f_connected5=nn.Linear(hidden4,hidden5)\n",
    "        self.f_connected6=nn.Linear(hidden5,hidden6)\n",
    "        self.f_connected7=nn.Linear(hidden6,hidden7)\n",
    "        self.f_connected8=nn.Linear(hidden7,hidden8)\n",
    "        self.f_connected9=nn.Linear(hidden8,hidden9)\n",
    "        self.out=nn.Linear(hidden9,out_features)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.f_connected1(x))\n",
    "        x=F.relu(self.f_connected2(x))\n",
    "        x=F.relu(self.f_connected3(x))\n",
    "        x=F.relu(self.f_connected4(x))\n",
    "        x=F.relu(self.f_connected5(x))\n",
    "        x=F.relu(self.f_connected6(x))\n",
    "        x=F.relu(self.f_connected7(x))\n",
    "        x=F.relu(self.f_connected8(x))\n",
    "        x=F.relu(self.f_connected9(x))\n",
    "        x=self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a59502ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(20)\n",
    "model = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50d0283a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Decoder(\n",
       "  (f_connected1): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (f_connected2): Linear(in_features=8, out_features=200, bias=True)\n",
       "  (f_connected3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (f_connected4): Linear(in_features=200, out_features=300, bias=True)\n",
       "  (f_connected5): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (f_connected6): Linear(in_features=300, out_features=400, bias=True)\n",
       "  (f_connected7): Linear(in_features=400, out_features=400, bias=True)\n",
       "  (f_connected8): Linear(in_features=400, out_features=300, bias=True)\n",
       "  (f_connected9): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (out): Linear(in_features=300, out_features=2, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98fffaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fc4b8c18820>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44418bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce7c8723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 and the loss: 0.6994479298591614\n",
      "Epoch number: 11 and the loss: 0.6807885766029358\n",
      "Epoch number: 21 and the loss: 0.6516156196594238\n",
      "Epoch number: 31 and the loss: 0.6306445002555847\n",
      "Epoch number: 41 and the loss: 0.6166210174560547\n",
      "Epoch number: 51 and the loss: 0.5757931470870972\n",
      "Epoch number: 61 and the loss: 0.5477321147918701\n",
      "Epoch number: 71 and the loss: 0.5501350164413452\n",
      "Epoch number: 81 and the loss: 0.541769802570343\n",
      "Epoch number: 91 and the loss: 0.5239008069038391\n",
      "Epoch number: 101 and the loss: 0.5185975432395935\n",
      "Epoch number: 111 and the loss: 0.526075005531311\n",
      "Epoch number: 121 and the loss: 0.5419977307319641\n",
      "Epoch number: 131 and the loss: 0.508708655834198\n",
      "Epoch number: 141 and the loss: 0.49814125895500183\n",
      "Epoch number: 151 and the loss: 0.4873463213443756\n",
      "Epoch number: 161 and the loss: 0.47971105575561523\n",
      "Epoch number: 171 and the loss: 0.4749397337436676\n",
      "Epoch number: 181 and the loss: 0.4853869676589966\n",
      "Epoch number: 191 and the loss: 0.48851099610328674\n",
      "Epoch number: 201 and the loss: 0.4815758168697357\n",
      "Epoch number: 211 and the loss: 0.4638412594795227\n",
      "Epoch number: 221 and the loss: 0.4751475751399994\n",
      "Epoch number: 231 and the loss: 0.45766469836235046\n",
      "Epoch number: 241 and the loss: 0.48991793394088745\n",
      "Epoch number: 251 and the loss: 0.46003299951553345\n",
      "Epoch number: 261 and the loss: 0.456523060798645\n",
      "Epoch number: 271 and the loss: 0.451443076133728\n",
      "Epoch number: 281 and the loss: 0.49172818660736084\n",
      "Epoch number: 291 and the loss: 0.4534727931022644\n",
      "Epoch number: 301 and the loss: 0.4735989272594452\n",
      "Epoch number: 311 and the loss: 0.46007436513900757\n",
      "Epoch number: 321 and the loss: 0.4749120771884918\n",
      "Epoch number: 331 and the loss: 0.4534558057785034\n",
      "Epoch number: 341 and the loss: 0.4456106424331665\n",
      "Epoch number: 351 and the loss: 0.44566768407821655\n",
      "Epoch number: 361 and the loss: 0.449868768453598\n",
      "Epoch number: 371 and the loss: 0.44445058703422546\n",
      "Epoch number: 381 and the loss: 0.44217562675476074\n",
      "Epoch number: 391 and the loss: 0.4686286747455597\n",
      "Epoch number: 401 and the loss: 0.46138590574264526\n",
      "Epoch number: 411 and the loss: 0.46292051672935486\n",
      "Epoch number: 421 and the loss: 0.46894127130508423\n",
      "Epoch number: 431 and the loss: 0.4549199640750885\n",
      "Epoch number: 441 and the loss: 0.43369922041893005\n",
      "Epoch number: 451 and the loss: 0.4268139600753784\n",
      "Epoch number: 461 and the loss: 0.5056172013282776\n",
      "Epoch number: 471 and the loss: 0.47482794523239136\n",
      "Epoch number: 481 and the loss: 0.5668880939483643\n",
      "Epoch number: 491 and the loss: 0.525562047958374\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "final_losses = []\n",
    "for i in range(epochs):\n",
    "    i = i + 1\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss=loss_function(y_pred, y_train)\n",
    "    final_losses.append(loss.item())\n",
    "    if i%10==1:\n",
    "        print(\"Epoch number: {} and the loss: {}\".format(i, loss.item()))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e368192",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3787ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=torch.FloatTensor(X_train)\n",
    "X_test=torch.FloatTensor(X_test)\n",
    "y_train=torch.LongTensor(y_train)\n",
    "y_test=torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9332cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self,input_features=8,hidden1=8,hidden2=200,hidden3=200,hidden4=300,hidden5=300,hidden6=400,hidden7=400, out_features=1):\n",
    "        super().__init__()\n",
    "        self.f_connected1=nn.Linear(input_features,hidden1)\n",
    "        self.f_connected2=nn.Linear(hidden1,hidden2)\n",
    "        #self.f_connected3=nn.Linear(hidden2,hidden3)\n",
    "        self.f_connected4=nn.Linear(hidden3,hidden4)\n",
    "        #self.f_connected5=nn.Linear(hidden4,hidden5)\n",
    "        self.f_connected6=nn.Linear(hidden5,hidden6)\n",
    "        self.f_connected7=nn.Linear(hidden6,hidden7)\n",
    "        #reshape using tensor_name.reshape(20,20,1)\n",
    "        self.conv1 = torch.nn.Conv2d(1, 100, kernel_size = (2,6), stride = 1)\n",
    "        self.f_connected8=nn.Linear(1800,35)\n",
    "        self.out=nn.Linear(35,out_features)\n",
    "    def forward(self,x):\n",
    "        dropout=nn.Dropout(p=0.2)\n",
    "        pooling=nn.MaxPool2d((2,6))\n",
    "        x=F.relu(self.f_connected1(x))\n",
    "        x=F.relu(self.f_connected2(x))\n",
    "        dropout(x)\n",
    "        #x=F.relu(self.f_connected3(x))\n",
    "        x=F.relu(self.f_connected4(x))\n",
    "        dropout(x)\n",
    "        #x=F.relu(self.f_connected5(x))\n",
    "        x=F.relu(self.f_connected6(x))\n",
    "        x=F.relu(self.f_connected7(x))\n",
    "        #print(x.shape)\n",
    "        x=x.view(-1,1,20,20)\n",
    "        x=F.relu(self.conv1(x))\n",
    "        x = dropout(x)\n",
    "        x = pooling(x)\n",
    "        x = dropout(x)\n",
    "        x=x.view(-1, 9*2*100)\n",
    "        #x = torch.flatten(x)\n",
    "        #x.reshape(-1)\n",
    "        #x.flatten()\n",
    "        #x.reshape([1,9*2*100])\n",
    "        x=F.relu(self.f_connected8(x))\n",
    "        x=F.sigmoid(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c65c82c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(20)\n",
    "model_classifier = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "227c530b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Classifier(\n",
       "  (f_connected1): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (f_connected2): Linear(in_features=8, out_features=200, bias=True)\n",
       "  (f_connected4): Linear(in_features=200, out_features=300, bias=True)\n",
       "  (f_connected6): Linear(in_features=300, out_features=400, bias=True)\n",
       "  (f_connected7): Linear(in_features=400, out_features=400, bias=True)\n",
       "  (conv1): Conv2d(1, 100, kernel_size=(2, 6), stride=(1, 1))\n",
       "  (f_connected8): Linear(in_features=1800, out_features=35, bias=True)\n",
       "  (out): Linear(in_features=35, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classifier.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b575894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_classifier.parameters(), lr = 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2529fd8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([691])) that is different to the input size (torch.Size([691, 1])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m i \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_classifier\u001b[38;5;241m.\u001b[39mforward(X_train)\n\u001b[0;32m----> 6\u001b[0m loss\u001b[38;5;241m=\u001b[39m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m final_losses_classifier\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:613\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:3074\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3072\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3074\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3075\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3076\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3077\u001b[0m     )\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3080\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([691])) that is different to the input size (torch.Size([691, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "epochs = 600\n",
    "final_losses_classifier = []\n",
    "for i in range(epochs):\n",
    "    i = i + 1\n",
    "    y_pred = model_classifier.forward(X_train)\n",
    "    loss=loss_function(y_pred, y_train)\n",
    "    final_losses_classifier.append(loss.item())\n",
    "    if i%10==1:\n",
    "        print(\"Epoch number: {} and the loss: {}\".format(i, loss.item()))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bf0a26",
   "metadata": {},
   "source": [
    "#### Check:\n",
    "In the nn made in classfier, the output layer has 2 neurons instead of 1 as given in the paper\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
